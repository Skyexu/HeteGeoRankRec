Dataset: ../data/filmtrust/rating
All dataset files [..\data\filmtrust\rating\ratings_0.txt, ..\data\filmtrust\rating\ratings_1.txt, ..\data\filmtrust\rating\ratings_2.txt, ..\data\filmtrust\rating\ratings_3.txt]
All dataset files size 411942
Now loading dataset file ratings_0
Now loading dataset file ratings_1
Now loading dataset file ratings_2
Now loading dataset file ratings_3
Transform data to Convertor successfully!
Split data to train Set and test Set successfully!
Data size of training is 28408
Data size of testing is 7086
Job Setup completed.
Job Train completed.
Job End.
Evaluator value:MAE is 1.293515302260018
Evaluator value:RMSE is 1.572256549107645
Evaluator value:MSE is 2.4719906562118803
Evaluator value:MPE is 0.9961896697713802
Result path is ../result/filmtrust/rating-randomguess-output/randomguess
Dataset: ../data/filmtrust/rating
All dataset files [..\data\filmtrust\rating\ratings_0.txt, ..\data\filmtrust\rating\ratings_1.txt, ..\data\filmtrust\rating\ratings_2.txt, ..\data\filmtrust\rating\ratings_3.txt]
All dataset files size 411942
Now loading dataset file ratings_0
Now loading dataset file ratings_1
Now loading dataset file ratings_2
Now loading dataset file ratings_3
Transform data to Convertor successfully!
Split data to train Set and test Set successfully!
Data size of training is 28408
Data size of testing is 7086
Job Setup completed.
WBPRRecommender iter 1: loss = 43670.24198954935, delta_loss = -43670.242
WBPRRecommender iter 2: loss = 31903.679971365957, delta_loss = 11766.5625
WBPRRecommender iter 3: loss = 28860.775436085132, delta_loss = 3042.9045
WBPRRecommender iter 4: loss = 26921.91818568198, delta_loss = 1938.8573
WBPRRecommender iter 5: loss = 25439.354792090162, delta_loss = 1482.5634
WBPRRecommender iter 6: loss = 24332.940397933413, delta_loss = 1106.4144
WBPRRecommender iter 7: loss = 23509.292237065267, delta_loss = 823.64813
WBPRRecommender iter 8: loss = 22851.05215654313, delta_loss = 658.24005
WBPRRecommender iter 9: loss = 22377.823162279146, delta_loss = 473.229
WBPRRecommender iter 10: loss = 21885.16297876733, delta_loss = 492.6602
WBPRRecommender iter 11: loss = 21519.37393397085, delta_loss = 365.78903
WBPRRecommender iter 12: loss = 21203.635548070386, delta_loss = 315.73837
WBPRRecommender iter 13: loss = 20853.129940659743, delta_loss = 350.5056
WBPRRecommender iter 14: loss = 20623.033309743285, delta_loss = 230.09663
WBPRRecommender iter 15: loss = 20381.81078243902, delta_loss = 241.22253
WBPRRecommender iter 16: loss = 20206.044281730636, delta_loss = 175.7665
WBPRRecommender iter 17: loss = 19982.587478922633, delta_loss = 223.4568
WBPRRecommender iter 18: loss = 19803.636965430887, delta_loss = 178.95052
WBPRRecommender iter 19: loss = 19653.623873631266, delta_loss = 150.01309
WBPRRecommender iter 20: loss = 19536.906468311623, delta_loss = 116.71741
Job Train completed.
Job End.
Evaluator value:AUC top 10 is 0.7275384122129623
Evaluator value:PRECISION top 10 is 0.22699289660615612
Evaluator value:AP top 10 is 0.22751119556097998
Evaluator value:RR top 10 is 0.2810588692198794
Evaluator value:RECALL top 10 is 0.27581908882095807
Evaluator value:Novelty top 10 is 18.793224453840274
Evaluator value:NDCG top 10 is 0.26483508063076955
Evaluator value:Entropy top 10 is 17.548868727457272
Result path is ../result/filmtrust/rating-wbpr-output/wbpr
Dataset: ../data/filmtrust/rating
All dataset files [..\data\filmtrust\rating\ratings_0.txt, ..\data\filmtrust\rating\ratings_1.txt, ..\data\filmtrust\rating\ratings_2.txt, ..\data\filmtrust\rating\ratings_3.txt]
All dataset files size 411942
Now loading dataset file ratings_0
Now loading dataset file ratings_1
Now loading dataset file ratings_2
Now loading dataset file ratings_3
Transform data to Convertor successfully!
Split data to train Set and test Set successfully!
Data size of training is 28408
Data size of testing is 7086
Dataset: ../data/filmtrust/rating
All dataset files [..\data\filmtrust\rating\ratings_0.txt, ..\data\filmtrust\rating\ratings_1.txt, ..\data\filmtrust\rating\ratings_2.txt, ..\data\filmtrust\rating\ratings_3.txt]
All dataset files size 411942
Now loading dataset file ratings_0
Now loading dataset file ratings_1
Now loading dataset file ratings_2
Now loading dataset file ratings_3
Transform data to Convertor successfully!
Split data to train Set and test Set successfully!
Data size of training is 28408
Data size of testing is 7086
Dataset: ../data/filmtrust/rating
All dataset files [..\data\filmtrust\rating\ratings_0.txt, ..\data\filmtrust\rating\ratings_1.txt, ..\data\filmtrust\rating\ratings_2.txt, ..\data\filmtrust\rating\ratings_3.txt]
All dataset files size 411942
Now loading dataset file ratings_0
Now loading dataset file ratings_1
Now loading dataset file ratings_2
Now loading dataset file ratings_3
Transform data to Convertor successfully!
Split data to train Set and test Set successfully!
Data size of training is 28408
Data size of testing is 7086
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Mon Apr 16 16:18:37 CST 2018
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Mon Apr 16 16:18:38 CST 2018
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Mon Apr 16 16:18:38 CST 2018
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Mon Apr 16 16:18:38 CST 2018
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Mon Apr 16 16:18:38 CST 2018
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Mon Apr 16 16:18:38 CST 2018
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Mon Apr 16 16:18:39 CST 2018
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Mon Apr 16 16:18:39 CST 2018
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Mon Apr 16 16:18:39 CST 2018
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Mon Apr 16 16:18:39 CST 2018
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Mon Apr 16 16:18:40 CST 2018
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Mon Apr 16 16:18:40 CST 2018
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Mon Apr 16 16:18:40 CST 2018
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Mon Apr 16 16:18:40 CST 2018
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Mon Apr 16 16:18:41 CST 2018
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Mon Apr 16 16:18:41 CST 2018
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Mon Apr 16 16:18:41 CST 2018
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Mon Apr 16 16:18:41 CST 2018
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Mon Apr 16 16:18:41 CST 2018
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Mon Apr 16 16:18:42 CST 2018
Job Train completed.
Job End.
Evaluator value:AP top 10 is 0.4861256451190488
Evaluator value:RECALL top 10 is 0.6341464251290702
Evaluator value:Novelty top 10 is 15.654470311176437
Evaluator value:RR top 10 is 0.6347872113854757
Evaluator value:AUC top 10 is 0.9230535402989238
Evaluator value:NDCG top 10 is 0.5753609458360556
Evaluator value:Entropy top 10 is 24.249124296947112
Evaluator value:PRECISION top 10 is 0.3456985003946344
Result path is ../result/filmtrust/rating-wrmf-output/wrmf
Dataset: ../data/filmtrust/rating
All dataset files [..\data\filmtrust\rating\ratings_0.txt, ..\data\filmtrust\rating\ratings_1.txt, ..\data\filmtrust\rating\ratings_2.txt, ..\data\filmtrust\rating\ratings_3.txt]
All dataset files size 411942
Now loading dataset file ratings_0
Now loading dataset file ratings_1
Now loading dataset file ratings_2
Now loading dataset file ratings_3
Transform data to Convertor successfully!
Split data to train Set and test Set successfully!
Data size of training is 28408
Data size of testing is 7086
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Mon Apr 16 16:19:44 CST 2018
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Mon Apr 16 16:19:44 CST 2018
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Mon Apr 16 16:19:45 CST 2018
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Mon Apr 16 16:19:45 CST 2018
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Mon Apr 16 16:19:46 CST 2018
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Mon Apr 16 16:19:47 CST 2018
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Mon Apr 16 16:19:48 CST 2018
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Mon Apr 16 16:19:48 CST 2018
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Mon Apr 16 16:19:48 CST 2018
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Mon Apr 16 16:19:48 CST 2018
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Mon Apr 16 16:19:48 CST 2018
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Mon Apr 16 16:19:48 CST 2018
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Mon Apr 16 16:19:49 CST 2018
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Mon Apr 16 16:19:49 CST 2018
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Mon Apr 16 16:19:49 CST 2018
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Mon Apr 16 16:19:49 CST 2018
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Mon Apr 16 16:19:49 CST 2018
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Mon Apr 16 16:19:49 CST 2018
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Mon Apr 16 16:19:49 CST 2018
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Mon Apr 16 16:19:49 CST 2018
Job Train completed.
Job End.
Evaluator value:AP top 10 is 0.4861256451190488
Evaluator value:RECALL top 10 is 0.6341464251290702
Evaluator value:Novelty top 10 is 15.654470311176437
Evaluator value:RR top 10 is 0.6347872113854757
Evaluator value:AUC top 10 is 0.9230535402989238
Evaluator value:NDCG top 10 is 0.5753609458360556
Evaluator value:Entropy top 10 is 24.249124296947112
Evaluator value:PRECISION top 10 is 0.3456985003946344
Result path is ../result/filmtrust/rating-wrmf-output/wrmf
Dataset: ../data/filmtrust/rating
All dataset files [..\data\filmtrust\rating\ratings_0.txt, ..\data\filmtrust\rating\ratings_1.txt, ..\data\filmtrust\rating\ratings_2.txt, ..\data\filmtrust\rating\ratings_3.txt]
All dataset files size 411942
Now loading dataset file ratings_0
Now loading dataset file ratings_1
Now loading dataset file ratings_2
Now loading dataset file ratings_3
Transform data to Convertor successfully!
Split data to train Set and test Set successfully!
Data size of training is 28408
Data size of testing is 7086
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Mon Apr 16 16:54:57 CST 2018
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Mon Apr 16 16:54:57 CST 2018
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Mon Apr 16 16:54:58 CST 2018
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Mon Apr 16 16:54:58 CST 2018
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Mon Apr 16 16:54:58 CST 2018
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Mon Apr 16 16:54:58 CST 2018
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Mon Apr 16 16:54:59 CST 2018
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Mon Apr 16 16:54:59 CST 2018
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Mon Apr 16 16:54:59 CST 2018
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Mon Apr 16 16:54:59 CST 2018
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Mon Apr 16 16:55:00 CST 2018
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Mon Apr 16 16:55:00 CST 2018
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Mon Apr 16 16:55:00 CST 2018
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Mon Apr 16 16:55:00 CST 2018
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Mon Apr 16 16:55:01 CST 2018
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Mon Apr 16 16:55:01 CST 2018
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Mon Apr 16 16:55:01 CST 2018
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Mon Apr 16 16:55:01 CST 2018
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Mon Apr 16 16:55:01 CST 2018
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Mon Apr 16 16:55:01 CST 2018
Job Train completed.
Job End.
Evaluator value:AP top 10 is 0.4861256451190488
Evaluator value:RECALL top 10 is 0.6341464251290702
Evaluator value:Novelty top 10 is 15.654470311176437
Evaluator value:RR top 10 is 0.6347872113854757
Evaluator value:AUC top 10 is 0.9230535402989238
Evaluator value:NDCG top 10 is 0.5753609458360556
Evaluator value:Entropy top 10 is 24.249124296947112
Evaluator value:PRECISION top 10 is 0.3456985003946344
Result path is ../result/filmtrust/rating-wrmf-output/wrmf
Dataset: ../data/filmtrust/rating
All dataset files [..\data\filmtrust\rating\ratings_0.txt, ..\data\filmtrust\rating\ratings_1.txt, ..\data\filmtrust\rating\ratings_2.txt, ..\data\filmtrust\rating\ratings_3.txt]
All dataset files size 411942
Now loading dataset file ratings_0
Now loading dataset file ratings_1
Now loading dataset file ratings_2
Now loading dataset file ratings_3
Transform data to Convertor successfully!
Split data to train Set and test Set successfully!
Data size of training is 28408
Data size of testing is 7086
Job Setup completed.
FISMaucRecommender iter 1: loss = 2350862.222525286, delta_loss = -2350862.2
FISMaucRecommender iter 2: loss = 2173254.4890639507, delta_loss = 177607.73
FISMaucRecommender iter 3: loss = 2022634.620305618, delta_loss = 150619.88
FISMaucRecommender iter 4: loss = 1888554.3198345457, delta_loss = 134080.3
FISMaucRecommender iter 5: loss = 1774866.996592405, delta_loss = 113687.32
Job Train completed.
Job End.
Evaluator value:RECALL top 10 is 0.6082224803497397
Evaluator value:Entropy top 10 is 16.08687352955666
Evaluator value:AUC top 10 is 0.9212938164759601
Evaluator value:NDCG top 10 is 0.5327943258696286
Evaluator value:PRECISION top 10 is 0.341278610891872
Evaluator value:RR top 10 is 0.5865868631062011
Evaluator value:AP top 10 is 0.43704066594043806
Evaluator value:Novelty top 10 is 11.569415301996916
Result path is ../result/filmtrust/rating-fismauc-output/fismauc
Dataset: ../data/filmtrust/rating
All dataset files [..\data\filmtrust\rating\ratings_0.txt, ..\data\filmtrust\rating\ratings_1.txt, ..\data\filmtrust\rating\ratings_2.txt, ..\data\filmtrust\rating\ratings_3.txt]
All dataset files size 411942
Now loading dataset file ratings_0
Now loading dataset file ratings_1
Now loading dataset file ratings_2
Now loading dataset file ratings_3
Transform data to Convertor successfully!
Split data to train Set and test Set successfully!
Data size of training is 28408
Data size of testing is 7086
Transform data to Feature successfully!
Job Setup completed.
SocialMFRecommender iter 1: loss = 1331.2675680392201, delta_loss = -1331.2676
SocialMFRecommender iter 2: loss = 1245.8894497966648, delta_loss = 85.37812
SocialMFRecommender iter 3: loss = 1187.5834288855922, delta_loss = 58.306023
SocialMFRecommender iter 4: loss = 1146.9831581397661, delta_loss = 40.60027
SocialMFRecommender iter 5: loss = 1116.3006121711053, delta_loss = 30.682547
SocialMFRecommender iter 6: loss = 1091.2211128125182, delta_loss = 25.0795
SocialMFRecommender iter 7: loss = 1069.7863286513686, delta_loss = 21.434784
SocialMFRecommender iter 8: loss = 1050.917976542136, delta_loss = 18.868353
SocialMFRecommender iter 9: loss = 1033.9590435991233, delta_loss = 16.958933
SocialMFRecommender iter 10: loss = 1018.4992403076105, delta_loss = 15.459804
SocialMFRecommender iter 11: loss = 1004.2751238190322, delta_loss = 14.224116
SocialMFRecommender iter 12: loss = 991.1082635446108, delta_loss = 13.166861
SocialMFRecommender iter 13: loss = 978.8694624506469, delta_loss = 12.238801
SocialMFRecommender iter 14: loss = 967.4591424291406, delta_loss = 11.41032
SocialMFRecommender iter 15: loss = 956.7966308206137, delta_loss = 10.662512
SocialMFRecommender iter 16: loss = 946.8141133557579, delta_loss = 9.982517
SocialMFRecommender iter 17: loss = 937.4530576953435, delta_loss = 9.361055
SocialMFRecommender iter 18: loss = 928.661998552384, delta_loss = 8.7910595
SocialMFRecommender iter 19: loss = 920.3951073331232, delta_loss = 8.2668915
SocialMFRecommender iter 20: loss = 912.6112293988765, delta_loss = 7.783878
SocialMFRecommender iter 21: loss = 905.2732056851279, delta_loss = 7.3380237
SocialMFRecommender iter 22: loss = 898.3473690703772, delta_loss = 6.9258366
SocialMFRecommender iter 23: loss = 891.8031492156305, delta_loss = 6.54422
SocialMFRecommender iter 24: loss = 885.6127461600332, delta_loss = 6.190403
SocialMFRecommender iter 25: loss = 879.7508494359802, delta_loss = 5.8618965
SocialMFRecommender iter 26: loss = 874.1943895333841, delta_loss = 5.55646
SocialMFRecommender iter 27: loss = 868.9223144757854, delta_loss = 5.272075
SocialMFRecommender iter 28: loss = 863.91538757666, delta_loss = 5.006927
SocialMFRecommender iter 29: loss = 859.1560041491592, delta_loss = 4.759383
SocialMFRecommender iter 30: loss = 854.6280257250062, delta_loss = 4.5279784
SocialMFRecommender iter 31: loss = 850.3166306313872, delta_loss = 4.311395
SocialMFRecommender iter 32: loss = 846.2081798392898, delta_loss = 4.108451
SocialMFRecommender iter 33: loss = 842.2900969755705, delta_loss = 3.918083
SocialMFRecommender iter 34: loss = 838.5507613613727, delta_loss = 3.7393355
SocialMFRecommender iter 35: loss = 834.9794129265305, delta_loss = 3.5713484
SocialMFRecommender iter 36: loss = 831.5660678672815, delta_loss = 3.413345
SocialMFRecommender iter 37: loss = 828.3014439577988, delta_loss = 3.2646239
SocialMFRecommender iter 38: loss = 825.1768944858522, delta_loss = 3.1245494
SocialMFRecommender iter 39: loss = 822.1843498586888, delta_loss = 2.9925447
SocialMFRecommender iter 40: loss = 819.3162660025213, delta_loss = 2.868084
SocialMFRecommender iter 41: loss = 816.5655787598545, delta_loss = 2.7506874
SocialMFRecommender iter 42: loss = 813.9256635659748, delta_loss = 2.6399152
SocialMFRecommender iter 43: loss = 811.3902997595998, delta_loss = 2.535364
SocialMFRecommender iter 44: loss = 808.953638949974, delta_loss = 2.4366608
SocialMFRecommender iter 45: loss = 806.6101769262993, delta_loss = 2.343462
SocialMFRecommender iter 46: loss = 804.3547286514925, delta_loss = 2.2554483
SocialMFRecommender iter 47: loss = 802.1824059349353, delta_loss = 2.1723228
SocialMFRecommender iter 48: loss = 800.0885974265616, delta_loss = 2.0938084
SocialMFRecommender iter 49: loss = 798.0689506176658, delta_loss = 2.019647
SocialMFRecommender iter 50: loss = 796.1193555738197, delta_loss = 1.9495951
SocialMFRecommender iter 51: loss = 794.2359301606823, delta_loss = 1.8834254
SocialMFRecommender iter 52: loss = 792.4150065569718, delta_loss = 1.8209236
SocialMFRecommender iter 53: loss = 790.6531188775672, delta_loss = 1.7618877
SocialMFRecommender iter 54: loss = 788.9469917565077, delta_loss = 1.7061272
SocialMFRecommender iter 55: loss = 787.2935297630144, delta_loss = 1.653462
SocialMFRecommender iter 56: loss = 785.6898075438629, delta_loss = 1.6037222
SocialMFRecommender iter 57: loss = 784.1330606040327, delta_loss = 1.556747
SocialMFRecommender iter 58: loss = 782.6206766520551, delta_loss = 1.5123839
SocialMFRecommender iter 59: loss = 781.1501874496699, delta_loss = 1.4704891
SocialMFRecommender iter 60: loss = 779.7192611170091, delta_loss = 1.4309263
SocialMFRecommender iter 61: loss = 778.3256948522173, delta_loss = 1.3935663
SocialMFRecommender iter 62: loss = 776.9674080327038, delta_loss = 1.3582869
SocialMFRecommender iter 63: loss = 775.6424356707045, delta_loss = 1.3249724
SocialMFRecommender iter 64: loss = 774.3489222001557, delta_loss = 1.2935134
SocialMFRecommender iter 65: loss = 773.0851155762371, delta_loss = 1.2638066
SocialMFRecommender iter 66: loss = 771.8493616706123, delta_loss = 1.2357539
SocialMFRecommender iter 67: loss = 770.6400989487252, delta_loss = 1.2092627
SocialMFRecommender iter 68: loss = 769.4558534158381, delta_loss = 1.1842456
SocialMFRecommender iter 69: loss = 768.2952338206228, delta_loss = 1.1606196
SocialMFRecommender iter 70: loss = 767.1569271050997, delta_loss = 1.1383067
SocialMFRecommender iter 71: loss = 766.0396940911203, delta_loss = 1.117233
SocialMFRecommender iter 72: loss = 764.9423653933414, delta_loss = 1.0973287
SocialMFRecommender iter 73: loss = 763.8638375491464, delta_loss = 1.0785278
SocialMFRecommender iter 74: loss = 762.8030693565992, delta_loss = 1.0607682
SocialMFRecommender iter 75: loss = 761.7590784108938, delta_loss = 1.043991
SocialMFRecommender iter 76: loss = 760.730937830991, delta_loss = 1.0281405
SocialMFRecommender iter 77: loss = 759.717773166968, delta_loss = 1.0131646
SocialMFRecommender iter 78: loss = 758.7187594804075, delta_loss = 0.99901366
SocialMFRecommender iter 79: loss = 757.7331185885038, delta_loss = 0.9856409
SocialMFRecommender iter 80: loss = 756.7601164644692, delta_loss = 0.97300214
SocialMFRecommender iter 81: loss = 755.7990607858017, delta_loss = 0.9610557
SocialMFRecommender iter 82: loss = 754.8492986227692, delta_loss = 0.94976217
SocialMFRecommender iter 83: loss = 753.9102142594426, delta_loss = 0.93908435
SocialMFRecommender iter 84: loss = 752.9812271403241, delta_loss = 0.92898715
SocialMFRecommender iter 85: loss = 752.0617899351798, delta_loss = 0.9194372
SocialMFRecommender iter 86: loss = 751.1513867152075, delta_loss = 0.9104032
SocialMFRecommender iter 87: loss = 750.2495312348717, delta_loss = 0.90185547
SocialMFRecommender iter 88: loss = 749.3557653119514, delta_loss = 0.8937659
SocialMFRecommender iter 89: loss = 748.4696573009393, delta_loss = 0.88610804
SocialMFRecommender iter 90: loss = 747.5908006535878, delta_loss = 0.87885666
SocialMFRecommender iter 91: loss = 746.7188125613493, delta_loss = 0.8719881
SocialMFRecommender iter 92: loss = 745.8533326749338, delta_loss = 0.8654799
SocialMFRecommender iter 93: loss = 744.9940218955387, delta_loss = 0.8593108
SocialMFRecommender iter 94: loss = 744.1405612339867, delta_loss = 0.85346067
SocialMFRecommender iter 95: loss = 743.2926507329213, delta_loss = 0.8479105
SocialMFRecommender iter 96: loss = 742.4500084485837, delta_loss = 0.8426423
SocialMFRecommender iter 97: loss = 741.612369487752, delta_loss = 0.837639
SocialMFRecommender iter 98: loss = 740.7794850972625, delta_loss = 0.8328844
SocialMFRecommender iter 99: loss = 739.9511218019334, delta_loss = 0.8283633
SocialMFRecommender iter 100: loss = 739.1270605886141, delta_loss = 0.8240612
Job Train completed.
Job End.
Evaluator value:MSE is 0.6708377366514289
Evaluator value:RMSE is 0.8190468464327476
Evaluator value:MAE is 0.6377885622447891
Evaluator value:MPE is 0.9911092294665538
Result path is ../result/filmtrust/rating-socialmf-output/socialmf
Dataset: ../data/filmtrust/rating
All dataset files [..\data\filmtrust\rating\ratings_0.txt, ..\data\filmtrust\rating\ratings_1.txt, ..\data\filmtrust\rating\ratings_2.txt, ..\data\filmtrust\rating\ratings_3.txt]
All dataset files size 411942
Now loading dataset file ratings_0
Now loading dataset file ratings_1
Now loading dataset file ratings_2
Now loading dataset file ratings_3
Transform data to Convertor successfully!
Split data to train Set and test Set successfully!
Data size of training is 28408
Data size of testing is 7086
Transform data to Feature successfully!
Job Setup completed.
Dataset: ../data/filmtrust/rating
All dataset files [..\data\filmtrust\rating\ratings_0.txt, ..\data\filmtrust\rating\ratings_1.txt, ..\data\filmtrust\rating\ratings_2.txt, ..\data\filmtrust\rating\ratings_3.txt]
All dataset files size 411942
Now loading dataset file ratings_0
Now loading dataset file ratings_1
Now loading dataset file ratings_2
Now loading dataset file ratings_3
SocialMFRecommender iter 1: loss = 1331.2675680392201, delta_loss = -1331.2676
SocialMFRecommender iter 2: loss = 1245.8894497966648, delta_loss = 85.37812
SocialMFRecommender iter 3: loss = 1187.5834288855922, delta_loss = 58.306023
SocialMFRecommender iter 4: loss = 1146.9831581397661, delta_loss = 40.60027
SocialMFRecommender iter 5: loss = 1116.3006121711053, delta_loss = 30.682547
SocialMFRecommender iter 6: loss = 1091.2211128125182, delta_loss = 25.0795
SocialMFRecommender iter 7: loss = 1069.7863286513686, delta_loss = 21.434784
SocialMFRecommender iter 8: loss = 1050.917976542136, delta_loss = 18.868353
SocialMFRecommender iter 9: loss = 1033.9590435991233, delta_loss = 16.958933
SocialMFRecommender iter 10: loss = 1018.4992403076105, delta_loss = 15.459804
SocialMFRecommender iter 11: loss = 1004.2751238190322, delta_loss = 14.224116
SocialMFRecommender iter 12: loss = 991.1082635446108, delta_loss = 13.166861
SocialMFRecommender iter 13: loss = 978.8694624506469, delta_loss = 12.238801
SocialMFRecommender iter 14: loss = 967.4591424291406, delta_loss = 11.41032
Dataset: ../data/filmtrust/rating
All dataset files [..\data\filmtrust\rating\ratings_0.txt, ..\data\filmtrust\rating\ratings_1.txt, ..\data\filmtrust\rating\ratings_2.txt, ..\data\filmtrust\rating\ratings_3.txt]
All dataset files size 411942
Now loading dataset file ratings_0
Now loading dataset file ratings_1
Now loading dataset file ratings_2
Now loading dataset file ratings_3
Dataset: ../data/filmtrust/rating
All dataset files [..\data\filmtrust\rating\ratings_0.txt, ..\data\filmtrust\rating\ratings_1.txt, ..\data\filmtrust\rating\ratings_2.txt, ..\data\filmtrust\rating\ratings_3.txt]
All dataset files size 411942
Now loading dataset file ratings_0
Now loading dataset file ratings_1
Now loading dataset file ratings_2
Now loading dataset file ratings_3
Dataset: ../data/filmtrust/rating
All dataset files [..\data\filmtrust\rating\ratings_0.txt, ..\data\filmtrust\rating\ratings_1.txt, ..\data\filmtrust\rating\ratings_2.txt, ..\data\filmtrust\rating\ratings_3.txt]
All dataset files size 411942
Now loading dataset file ratings_0
Now loading dataset file ratings_1
Now loading dataset file ratings_2
Now loading dataset file ratings_3
Dataset: ../data/filmtrust/rating
All dataset files [..\data\filmtrust\rating\ratings_0.txt, ..\data\filmtrust\rating\ratings_1.txt, ..\data\filmtrust\rating\ratings_2.txt, ..\data\filmtrust\rating\ratings_3.txt]
All dataset files size 411942
Now loading dataset file ratings_0
Now loading dataset file ratings_1
Now loading dataset file ratings_2
Now loading dataset file ratings_3
Dataset: ../data/filmtrust/rating
All dataset files [..\data\filmtrust\rating\ratings_0.txt, ..\data\filmtrust\rating\ratings_1.txt, ..\data\filmtrust\rating\ratings_2.txt, ..\data\filmtrust\rating\ratings_3.txt]
All dataset files size 411942
Now loading dataset file ratings_0
Now loading dataset file ratings_1
Now loading dataset file ratings_2
Now loading dataset file ratings_3
Dataset: ...uare\process/小数据量\metapath\upcp.txt
All dataset files [D:\Works\论文\dataSet\experimentData\Foursquare\process\小数据量\metapath\upcp.txt]
All dataset files size 85545
Now loading dataset file upcp
Dataset: ...uare\process/小数据量\metapath\upcp.txt
All dataset files [D:\Works\论文\dataSet\experimentData\Foursquare\process\小数据量\metapath\upcp.txt]
All dataset files size 85545
Now loading dataset file upcp
Dataset: ...uare\process/小数据量\metapath\upcp.txt
All dataset files [D:\Works\论文\dataSet\experimentData\Foursquare\process\小数据量\metapath\upcp.txt]
All dataset files size 85545
Now loading dataset file upcp
Dataset: ...uare\process/小数据量\metapath\upcp.txt
All dataset files [D:\Works\论文\dataSet\experimentData\Foursquare\process\小数据量\metapath\upcp.txt]
All dataset files size 85545
Now loading dataset file upcp
Dataset: ...uare\process/小数据量\metapath\upcp.txt
All dataset files [D:\Works\论文\dataSet\experimentData\Foursquare\process\小数据量\metapath\upcp.txt]
All dataset files size 85545
Now loading dataset file upcp
poi lat lon data: ...oursquare\process/venue_lat_lon.txt
Dataset: ...uare\process/小数据量\metapath\upcp.txt
All dataset files [D:\Works\论文\dataSet\experimentData\Foursquare\process\小数据量\metapath\upcp.txt]
All dataset files size 85545
Now loading dataset file upcp
poi lat lon data: ...oursquare\process/venue_lat_lon.txt
Dataset: ...uare\process/小数据量\metapath\upcp.txt
All dataset files [D:\Works\论文\dataSet\experimentData\Foursquare\process\小数据量\metapath\upcp.txt]
All dataset files size 85545
Now loading dataset file upcp
poi lat lon data: ...oursquare\process/venue_lat_lon.txt
Dataset: ...uare\process/小数据量\metapath\upcp.txt
All dataset files [D:\Works\论文\dataSet\experimentData\Foursquare\process\小数据量\metapath\upcp.txt]
All dataset files size 85545
Now loading dataset file upcp
poi lat lon data: ...oursquare\process/venue_lat_lon.txt
Dataset: ...uare\process/小数据量\metapath\upcp.txt
All dataset files [D:\Works\论文\dataSet\experimentData\Foursquare\process\小数据量\metapath\upcp.txt]
All dataset files size 85545
Now loading dataset file upcp
poi lat lon data: ...oursquare\process/venue_lat_lon.txt
Dataset: ...uare\process/小数据量\metapath\upcp.txt
All dataset files [D:\Works\论文\dataSet\experimentData\Foursquare\process\小数据量\metapath\upcp.txt]
All dataset files size 2102748
Now loading dataset file upcp
poi lat lon data: ...oursquare\process/venue_lat_lon.txt
Dataset: ...uare\process/小数据量\metapath\upcp.txt
All dataset files [D:\Works\论文\dataSet\experimentData\Foursquare\process\小数据量\metapath\upcp.txt]
All dataset files size 2102748
Now loading dataset file upcp
poi lat lon data: ...oursquare\process/venue_lat_lon.txt
Dataset: ...uare\process/小数据量\metapath\upcp.txt
All dataset files [D:\Works\论文\dataSet\experimentData\Foursquare\process\小数据量\metapath\upcp.txt]
All dataset files size 2102748
Now loading dataset file upcp
poi lat lon data: ...oursquare\process/venue_lat_lon.txt
up data: ...ss/小数据量\user_chekin_venue_count.txt
Dataset: ...uare\process/小数据量\metapath\upcp.txt
All dataset files [D:\Works\论文\dataSet\experimentData\Foursquare\process\小数据量\metapath\upcp.txt]
All dataset files size 2102748
Now loading dataset file upcp
poi lat lon data: ...oursquare\process/venue_lat_lon.txt
up data: ...ss/小数据量\user_chekin_venue_count.txt
Dataset: ...uare\process/小数据量\metapath\upcp.txt
All dataset files [D:\Works\论文\dataSet\experimentData\Foursquare\process\小数据量\metapath\upcp.txt]
All dataset files size 2102748
Now loading dataset file upcp
poi lat lon data: ...\process/小数据量\venue_place_small.txt
up data: ...ss/小数据量\user_chekin_venue_count.txt
Dataset: ...uare\process/小数据量\metapath\upcp.txt
All dataset files [D:\Works\论文\dataSet\experimentData\Foursquare\process\小数据量\metapath\upcp.txt]
All dataset files size 431917
Now loading dataset file upcp
poi lat lon data: ...\process/小数据量\venue_place_small.txt
up data: ...ss/小数据量\user_chekin_venue_count.txt
Dataset: ...uare\process/小数据量\metapath\upcp.txt
All dataset files [D:\Works\论文\dataSet\experimentData\Foursquare\process\小数据量\metapath\upcp.txt]
All dataset files size 84729
Now loading dataset file upcp
poi lat lon data: ...\process/小数据量\venue_place_small.txt
up data: ...ss/小数据量\user_chekin_venue_count.txt
Dataset: ...uare\process/小数据量\metapath\upcp.txt
All dataset files [D:\Works\论文\dataSet\experimentData\Foursquare\process\小数据量\metapath\upcp.txt]
All dataset files size 84729
Now loading dataset file upcp
poi lat lon data: ...\process/小数据量\venue_place_small.txt
up data: ...ss/小数据量\user_chekin_venue_count.txt
Dataset: ...experiment_8_31//preference_uvc.txt
All dataset files [D:\Works\论文\dataSet\experimentData\Foursquare\process\experiment_8_31\preference_uvc.txt]
All dataset files size 216277
Now loading dataset file preference_uvc
Transform data to Convertor successfully!
Dataset: ...ss/experiment_8_31//newTest_uvc.txt
All dataset files [D:\Works\论文\dataSet\experimentData\Foursquare\process\experiment_8_31\newTest_uvc.txt]
All dataset files size 18322010
Now loading dataset file newTest_uvc
Split data to train Set and test Set successfully!
Data size of training is 13024
Data size of testing is 3595
Job Setup completed.
Job Train completed.
Job End.
Evaluator value:RECALL top 10 is 0.11885292405396719
Evaluator value:Novelty top 10 is 27.878464313453282
Evaluator value:Entropy top 10 is 10.725221762220986
Evaluator value:NDCG top 10 is 0.12566128703211396
Evaluator value:AP top 10 is 0.07197246854253106
Evaluator value:PRECISION top 10 is 0.05394932935916568
Evaluator value:AUC top 10 is 0.7189386452386894
Evaluator value:RR top 10 is 0.26495576372625546
Result path is D:/Works/论文/dataSet/experimentData/Foursquare/process/experiment_8_31/result//preference_uvc.txt-userknn-output/userknn
Dataset: ...ss/小数据量/user_chekin_venue_count.txt
All dataset files [D:\Works\论文\dataSet\experimentData\Foursquare\process\小数据量\user_chekin_venue_count.txt]
All dataset files size 16766
Now loading dataset file user_chekin_venue_count
Transform data to Convertor successfully!
Split data to train Set and test Set successfully!
Data size of training is 1035
Data size of testing is 272
Dataset: ...ss/小数据量/user_chekin_venue_count.txt
All dataset files [D:\Works\论文\dataSet\experimentData\Foursquare\process\小数据量\user_chekin_venue_count.txt]
All dataset files size 16766
Now loading dataset file user_chekin_venue_count
Transform data to Convertor successfully!
Split data to train Set and test Set successfully!
Data size of training is 1035
Data size of testing is 272
Dataset: ...ss/小数据量/user_chekin_venue_count.txt
All dataset files [D:\Works\论文\dataSet\experimentData\Foursquare\process\小数据量\user_chekin_venue_count.txt]
All dataset files size 16766
Now loading dataset file user_chekin_venue_count
Transform data to Convertor successfully!
Split data to train Set and test Set successfully!
Data size of training is 1035
Data size of testing is 272
Job Setup completed.
Job Train completed.
Job End.
Evaluator value:RECALL top 10 is 0.2610526315789474
Evaluator value:Novelty top 10 is 42.07918269103231
Evaluator value:Entropy top 10 is 19.340092209988452
Evaluator value:NDCG top 10 is 0.14262111845487083
Evaluator value:AP top 10 is 0.09235679476468948
Evaluator value:PRECISION top 10 is 0.041578947368421014
Evaluator value:AUC top 10 is 0.6468741300111768
Evaluator value:RR top 10 is 0.12601712614870506
Result path is D:/Works/论文/dataSet/experimentData/Foursquare/process/experiment_8_31/result//process/小数据量/user_chekin_venue_count.txt-userknn-output/userknn
Dataset: ...experiment_8_31//preference_uvc.txt
All dataset files [D:\Works\论文\dataSet\experimentData\Foursquare\process\experiment_8_31\preference_uvc.txt]
All dataset files size 216277
Now loading dataset file preference_uvc
Transform data to Convertor successfully!
Dataset: ...ss/experiment_8_31//newTest_uvc.txt
All dataset files [D:\Works\论文\dataSet\experimentData\Foursquare\process\experiment_8_31\newTest_uvc.txt]
All dataset files size 18322010
Now loading dataset file newTest_uvc
Split data to train Set and test Set successfully!
Data size of training is 13024
Data size of testing is 3595
Job Setup completed.
BPRRecommender iter 1: loss = 46615.01790784984, delta_loss = -46615.02
BPRRecommender iter 2: loss = 46335.845041401255, delta_loss = 279.17285
BPRRecommender iter 3: loss = 45999.17209580783, delta_loss = 336.67294
BPRRecommender iter 4: loss = 45520.11766435558, delta_loss = 479.05444
BPRRecommender iter 5: loss = 44652.90710207752, delta_loss = 867.2106
BPRRecommender iter 6: loss = 43298.4511489651, delta_loss = 1354.4559
BPRRecommender iter 7: loss = 41597.443836307284, delta_loss = 1701.0073
BPRRecommender iter 8: loss = 39560.524909730615, delta_loss = 2036.919
BPRRecommender iter 9: loss = 37310.35034942627, delta_loss = 2250.1746
BPRRecommender iter 10: loss = 35052.85988738467, delta_loss = 2257.4905
BPRRecommender iter 11: loss = 33062.466168884115, delta_loss = 1990.3937
BPRRecommender iter 12: loss = 31221.40644699659, delta_loss = 1841.0597
BPRRecommender iter 13: loss = 29772.816785319996, delta_loss = 1448.5897
BPRRecommender iter 14: loss = 28499.91032946752, delta_loss = 1272.9065
BPRRecommender iter 15: loss = 27220.231237190277, delta_loss = 1279.6791
BPRRecommender iter 16: loss = 26178.498376052616, delta_loss = 1041.7329
BPRRecommender iter 17: loss = 25293.683767085702, delta_loss = 884.81464
BPRRecommender iter 18: loss = 24694.811031826557, delta_loss = 598.87274
BPRRecommender iter 19: loss = 23923.127709702967, delta_loss = 771.68335
BPRRecommender iter 20: loss = 23443.601411186253, delta_loss = 479.5263
BPRRecommender iter 21: loss = 22830.24963536593, delta_loss = 613.35175
BPRRecommender iter 22: loss = 22355.042084093377, delta_loss = 475.20755
BPRRecommender iter 23: loss = 21917.27662234917, delta_loss = 437.76547
BPRRecommender iter 24: loss = 21513.12810453212, delta_loss = 404.14853
BPRRecommender iter 25: loss = 21296.522848860543, delta_loss = 216.60526
BPRRecommender iter 26: loss = 20799.7477556446, delta_loss = 496.7751
BPRRecommender iter 27: loss = 20645.637761399346, delta_loss = 154.11
BPRRecommender iter 28: loss = 20467.823888803516, delta_loss = 177.81387
BPRRecommender iter 29: loss = 20148.380506200054, delta_loss = 319.4434
BPRRecommender iter 30: loss = 19813.060822268104, delta_loss = 335.31967
Job Train completed.
Job End.
Evaluator value:PRECISION top 10 is 0.03338301043219079
Evaluator value:AP top 10 is 0.029633593377738583
Evaluator value:AUC top 10 is 0.6385303535948704
Evaluator value:RECALL top 10 is 0.06506172128579409
Evaluator value:NDCG top 10 is 0.0616558302567799
Evaluator value:Entropy top 10 is 40.68491182394576
Evaluator value:RR top 10 is 0.1343706384689992
Evaluator value:Novelty top 10 is 39.86605619007964
Result path is D:/Works/论文/dataSet/experimentData/Foursquare/process/experiment_8_31/result//preference_uvc.txt-bpr-output/bpr
Dataset: ...experiment_8_31//preference_uvc.txt
All dataset files [D:\Works\论文\dataSet\experimentData\Foursquare\process\experiment_8_31\preference_uvc.txt]
All dataset files size 216277
Now loading dataset file preference_uvc
Transform data to Convertor successfully!
Dataset: ...ss/experiment_8_31//newTest_uvc.txt
All dataset files [D:\Works\论文\dataSet\experimentData\Foursquare\process\experiment_8_31\newTest_uvc.txt]
All dataset files size 18322010
Now loading dataset file newTest_uvc
Split data to train Set and test Set successfully!
Data size of training is 13024
Data size of testing is 3595
Job Setup completed.
BPRRecommender iter 1: loss = 46661.00022404035, delta_loss = -46661.0
BPRRecommender iter 2: loss = 46140.30003449343, delta_loss = 520.7002
BPRRecommender iter 3: loss = 45478.39489970328, delta_loss = 661.90515
BPRRecommender iter 4: loss = 44506.4790622501, delta_loss = 971.91583
BPRRecommender iter 5: loss = 43091.7363097779, delta_loss = 1414.7428
BPRRecommender iter 6: loss = 41241.872299906936, delta_loss = 1849.864
BPRRecommender iter 7: loss = 38985.26623065454, delta_loss = 2256.606
BPRRecommender iter 8: loss = 36583.792131227, delta_loss = 2401.474
BPRRecommender iter 9: loss = 34096.19578667925, delta_loss = 2487.5964
BPRRecommender iter 10: loss = 31876.405277866328, delta_loss = 2219.7905
BPRRecommender iter 11: loss = 29967.89804195514, delta_loss = 1908.5072
BPRRecommender iter 12: loss = 28108.761434537486, delta_loss = 1859.1366
BPRRecommender iter 13: loss = 26693.012327772478, delta_loss = 1415.7491
BPRRecommender iter 14: loss = 25466.791723385573, delta_loss = 1226.2206
BPRRecommender iter 15: loss = 24218.81656464389, delta_loss = 1247.9752
BPRRecommender iter 16: loss = 23219.77425689008, delta_loss = 999.0423
BPRRecommender iter 17: loss = 22604.28170892394, delta_loss = 615.49255
BPRRecommender iter 18: loss = 21870.784624287946, delta_loss = 733.4971
BPRRecommender iter 19: loss = 21189.990545681543, delta_loss = 680.79407
BPRRecommender iter 20: loss = 20699.7047361501, delta_loss = 490.2858
BPRRecommender iter 21: loss = 20233.753569616132, delta_loss = 465.95117
BPRRecommender iter 22: loss = 19775.983882337627, delta_loss = 457.76968
BPRRecommender iter 23: loss = 19367.14548054019, delta_loss = 408.8384
BPRRecommender iter 24: loss = 19132.151804328987, delta_loss = 234.99368
BPRRecommender iter 25: loss = 18719.92009519154, delta_loss = 412.23172
BPRRecommender iter 26: loss = 18431.54022111985, delta_loss = 288.37988
BPRRecommender iter 27: loss = 18298.26649666442, delta_loss = 133.27373
BPRRecommender iter 28: loss = 17999.731554817998, delta_loss = 298.53494
BPRRecommender iter 29: loss = 17687.90272189222, delta_loss = 311.82883
BPRRecommender iter 30: loss = 17685.364275742377, delta_loss = 2.5384462
Job Train completed.
Job End.
Evaluator value:PRECISION top 10 is 0.033979135618479935
Evaluator value:AP top 10 is 0.030997725385898702
Evaluator value:AUC top 10 is 0.6421643262441189
Evaluator value:RECALL top 10 is 0.06522609708907365
Evaluator value:NDCG top 10 is 0.06309697122564506
Evaluator value:Entropy top 10 is 44.14999006799865
Evaluator value:RR top 10 is 0.1365623447590661
Evaluator value:Novelty top 10 is 41.313843062907516
Result path is D:/Works/论文/dataSet/experimentData/Foursquare/process/experiment_8_31/result//preference_uvc.txt-bpr-output/bpr
Dataset: ...experiment_8_31//preference_uvc.txt
All dataset files [D:\Works\论文\dataSet\experimentData\Foursquare\process\experiment_8_31\preference_uvc.txt]
All dataset files size 216277
Now loading dataset file preference_uvc
Transform data to Convertor successfully!
Dataset: ...ss/experiment_8_31//newTest_uvc.txt
All dataset files [D:\Works\论文\dataSet\experimentData\Foursquare\process\experiment_8_31\newTest_uvc.txt]
All dataset files size 18322010
Now loading dataset file newTest_uvc
Split data to train Set and test Set successfully!
Data size of training is 13024
Data size of testing is 3595
Job Setup completed.
BPRRecommender iter 1: loss = 46661.00022404035, delta_loss = -46661.0
BPRRecommender iter 2: loss = 46140.30003449343, delta_loss = 520.7002
BPRRecommender iter 3: loss = 45478.39489970328, delta_loss = 661.90515
BPRRecommender iter 4: loss = 44506.4790622501, delta_loss = 971.91583
BPRRecommender iter 5: loss = 43091.7363097779, delta_loss = 1414.7428
BPRRecommender iter 6: loss = 41241.872299906936, delta_loss = 1849.864
BPRRecommender iter 7: loss = 38985.26623065454, delta_loss = 2256.606
BPRRecommender iter 8: loss = 36583.792131227, delta_loss = 2401.474
BPRRecommender iter 9: loss = 34096.19578667925, delta_loss = 2487.5964
BPRRecommender iter 10: loss = 31876.405277866328, delta_loss = 2219.7905
Job Train completed.
Job End.
Evaluator value:PRECISION top 10 is 0.042921013412816796
Evaluator value:AP top 10 is 0.04616497701636267
Evaluator value:AUC top 10 is 0.6775947747263031
Evaluator value:RECALL top 10 is 0.09095263744249465
Evaluator value:NDCG top 10 is 0.08844347422676667
Evaluator value:Entropy top 10 is 25.723785148588
Evaluator value:RR top 10 is 0.18704433089678985
Evaluator value:Novelty top 10 is 33.0498375612432
Result path is D:/Works/论文/dataSet/experimentData/Foursquare/process/experiment_8_31/result//preference_uvc.txt-bpr-output/bpr
Dataset: ...experiment_8_31//preference_uvc.txt
All dataset files [D:\Works\论文\dataSet\experimentData\Foursquare\process\experiment_8_31\preference_uvc.txt]
All dataset files size 216277
Now loading dataset file preference_uvc
Transform data to Convertor successfully!
Dataset: ...ss/experiment_8_31//newTest_uvc.txt
All dataset files [D:\Works\论文\dataSet\experimentData\Foursquare\process\experiment_8_31\newTest_uvc.txt]
All dataset files size 18322010
Now loading dataset file newTest_uvc
Split data to train Set and test Set successfully!
Data size of training is 13024
Data size of testing is 3595
Job Setup completed.
BPRRecommender iter 1: loss = 46661.00022404035, delta_loss = -46661.0
BPRRecommender iter 2: loss = 46140.30003449343, delta_loss = 520.7002
BPRRecommender iter 3: loss = 45478.39489970328, delta_loss = 661.90515
BPRRecommender iter 4: loss = 44506.4790622501, delta_loss = 971.91583
BPRRecommender iter 5: loss = 43091.7363097779, delta_loss = 1414.7428
BPRRecommender iter 6: loss = 41241.872299906936, delta_loss = 1849.864
BPRRecommender iter 7: loss = 38985.26623065454, delta_loss = 2256.606
BPRRecommender iter 8: loss = 36583.792131227, delta_loss = 2401.474
BPRRecommender iter 9: loss = 34096.19578667925, delta_loss = 2487.5964
BPRRecommender iter 10: loss = 31876.405277866328, delta_loss = 2219.7905
BPRRecommender iter 11: loss = 29967.89804195514, delta_loss = 1908.5072
BPRRecommender iter 12: loss = 28108.761434537486, delta_loss = 1859.1366
BPRRecommender iter 13: loss = 26693.012327772478, delta_loss = 1415.7491
BPRRecommender iter 14: loss = 25466.791723385573, delta_loss = 1226.2206
BPRRecommender iter 15: loss = 24218.81656464389, delta_loss = 1247.9752
BPRRecommender iter 16: loss = 23219.77425689008, delta_loss = 999.0423
BPRRecommender iter 17: loss = 22604.28170892394, delta_loss = 615.49255
BPRRecommender iter 18: loss = 21870.784624287946, delta_loss = 733.4971
BPRRecommender iter 19: loss = 21189.990545681543, delta_loss = 680.79407
BPRRecommender iter 20: loss = 20699.7047361501, delta_loss = 490.2858
BPRRecommender iter 21: loss = 20233.753569616132, delta_loss = 465.95117
BPRRecommender iter 22: loss = 19775.983882337627, delta_loss = 457.76968
BPRRecommender iter 23: loss = 19367.14548054019, delta_loss = 408.8384
BPRRecommender iter 24: loss = 19132.151804328987, delta_loss = 234.99368
BPRRecommender iter 25: loss = 18719.92009519154, delta_loss = 412.23172
BPRRecommender iter 26: loss = 18431.54022111985, delta_loss = 288.37988
BPRRecommender iter 27: loss = 18298.26649666442, delta_loss = 133.27373
BPRRecommender iter 28: loss = 17999.731554817998, delta_loss = 298.53494
BPRRecommender iter 29: loss = 17687.90272189222, delta_loss = 311.82883
BPRRecommender iter 30: loss = 17685.364275742377, delta_loss = 2.5384462
BPRRecommender iter 31: loss = 17529.009465662853, delta_loss = 156.35481
BPRRecommender iter 32: loss = 17276.732802016995, delta_loss = 252.27666
BPRRecommender iter 33: loss = 17235.17254890189, delta_loss = 41.560253
BPRRecommender iter 34: loss = 17201.32761695922, delta_loss = 33.844933
BPRRecommender iter 35: loss = 17109.025600550816, delta_loss = 92.30202
BPRRecommender iter 36: loss = 17013.550323240837, delta_loss = 95.47528
BPRRecommender iter 37: loss = 16934.279168326037, delta_loss = 79.27116
BPRRecommender iter 38: loss = 16780.818639942572, delta_loss = 153.46053
BPRRecommender iter 39: loss = 16753.15217290646, delta_loss = 27.666468
BPRRecommender iter 40: loss = 16713.564779813227, delta_loss = 39.587395
Job Train completed.
Job End.
Evaluator value:PRECISION top 10 is 0.03263785394932941
Evaluator value:AP top 10 is 0.027946068572044354
Evaluator value:AUC top 10 is 0.6370009521631681
Evaluator value:RECALL top 10 is 0.0628304736083252
Evaluator value:NDCG top 10 is 0.058113928804260306
Evaluator value:Entropy top 10 is 47.85719459125794
Evaluator value:RR top 10 is 0.12039777162727987
Evaluator value:Novelty top 10 is 43.14768766631461
Result path is D:/Works/论文/dataSet/experimentData/Foursquare/process/experiment_8_31/result//preference_uvc.txt-bpr-output/bpr
Dataset: ...experiment_8_31//preference_uvc.txt
All dataset files [D:\Works\论文\dataSet\experimentData\Foursquare\process\experiment_8_31\preference_uvc.txt]
All dataset files size 216277
Now loading dataset file preference_uvc
Transform data to Convertor successfully!
Dataset: ...ss/experiment_8_31//newTest_uvc.txt
All dataset files [D:\Works\论文\dataSet\experimentData\Foursquare\process\experiment_8_31\newTest_uvc.txt]
All dataset files size 18322010
Now loading dataset file newTest_uvc
Split data to train Set and test Set successfully!
Data size of training is 13024
Data size of testing is 3595
Job Setup completed.
BPRRecommender iter 1: loss = 46661.00022404035, delta_loss = -46661.0
BPRRecommender iter 2: loss = 46140.30003449343, delta_loss = 520.7002
BPRRecommender iter 3: loss = 45478.39489970328, delta_loss = 661.90515
BPRRecommender iter 4: loss = 44506.4790622501, delta_loss = 971.91583
BPRRecommender iter 5: loss = 43091.7363097779, delta_loss = 1414.7428
BPRRecommender iter 6: loss = 41241.872299906936, delta_loss = 1849.864
BPRRecommender iter 7: loss = 38985.26623065454, delta_loss = 2256.606
BPRRecommender iter 8: loss = 36583.792131227, delta_loss = 2401.474
BPRRecommender iter 9: loss = 34096.19578667925, delta_loss = 2487.5964
BPRRecommender iter 10: loss = 31876.405277866328, delta_loss = 2219.7905
BPRRecommender iter 11: loss = 29967.89804195514, delta_loss = 1908.5072
BPRRecommender iter 12: loss = 28108.761434537486, delta_loss = 1859.1366
BPRRecommender iter 13: loss = 26693.012327772478, delta_loss = 1415.7491
BPRRecommender iter 14: loss = 25466.791723385573, delta_loss = 1226.2206
BPRRecommender iter 15: loss = 24218.81656464389, delta_loss = 1247.9752
BPRRecommender iter 16: loss = 23219.77425689008, delta_loss = 999.0423
BPRRecommender iter 17: loss = 22604.28170892394, delta_loss = 615.49255
BPRRecommender iter 18: loss = 21870.784624287946, delta_loss = 733.4971
BPRRecommender iter 19: loss = 21189.990545681543, delta_loss = 680.79407
BPRRecommender iter 20: loss = 20699.7047361501, delta_loss = 490.2858
BPRRecommender iter 21: loss = 20233.753569616132, delta_loss = 465.95117
BPRRecommender iter 22: loss = 19775.983882337627, delta_loss = 457.76968
BPRRecommender iter 23: loss = 19367.14548054019, delta_loss = 408.8384
BPRRecommender iter 24: loss = 19132.151804328987, delta_loss = 234.99368
BPRRecommender iter 25: loss = 18719.92009519154, delta_loss = 412.23172
BPRRecommender iter 26: loss = 18431.54022111985, delta_loss = 288.37988
BPRRecommender iter 27: loss = 18298.26649666442, delta_loss = 133.27373
BPRRecommender iter 28: loss = 17999.731554817998, delta_loss = 298.53494
BPRRecommender iter 29: loss = 17687.90272189222, delta_loss = 311.82883
BPRRecommender iter 30: loss = 17685.364275742377, delta_loss = 2.5384462
BPRRecommender iter 31: loss = 17529.009465662853, delta_loss = 156.35481
BPRRecommender iter 32: loss = 17276.732802016995, delta_loss = 252.27666
BPRRecommender iter 33: loss = 17235.17254890189, delta_loss = 41.560253
BPRRecommender iter 34: loss = 17201.32761695922, delta_loss = 33.844933
BPRRecommender iter 35: loss = 17109.025600550816, delta_loss = 92.30202
BPRRecommender iter 36: loss = 17013.550323240837, delta_loss = 95.47528
BPRRecommender iter 37: loss = 16934.279168326037, delta_loss = 79.27116
BPRRecommender iter 38: loss = 16780.818639942572, delta_loss = 153.46053
BPRRecommender iter 39: loss = 16753.15217290646, delta_loss = 27.666468
BPRRecommender iter 40: loss = 16713.564779813227, delta_loss = 39.587395
Job Train completed.
Job End.
Evaluator value:NDCG top 5 is 0.052693082700397624
Evaluator value:PRECISION top 5 is 0.04143070044709381
Evaluator value:Novelty top 5 is 20.51362368955304
Evaluator value:RR top 5 is 0.10792349726775959
Evaluator value:AUC top 5 is 0.5922788563944014
Evaluator value:AP top 5 is 0.029816194734227506
Evaluator value:RECALL top 5 is 0.04047045947428588
Evaluator value:Entropy top 5 is 26.859495764110736
Result path is D:/Works/论文/dataSet/experimentData/Foursquare/process/experiment_8_31/result//preference_uvc.txt-bpr-output/bpr
Dataset: ...experiment_8_31//preference_uvc.txt
All dataset files [D:\Works\论文\dataSet\experimentData\Foursquare\process\experiment_8_31\preference_uvc.txt]
All dataset files size 216277
Now loading dataset file preference_uvc
Transform data to Convertor successfully!
Dataset: ...ss/experiment_8_31//newTest_uvc.txt
All dataset files [D:\Works\论文\dataSet\experimentData\Foursquare\process\experiment_8_31\newTest_uvc.txt]
All dataset files size 18322010
Now loading dataset file newTest_uvc
Split data to train Set and test Set successfully!
Data size of training is 13024
Data size of testing is 3595
Job Setup completed.
BPRRecommender iter 1: loss = 46661.00022404035, delta_loss = -46661.0
BPRRecommender iter 2: loss = 46140.30003449343, delta_loss = 520.7002
BPRRecommender iter 3: loss = 45478.39489970328, delta_loss = 661.90515
BPRRecommender iter 4: loss = 44506.4790622501, delta_loss = 971.91583
BPRRecommender iter 5: loss = 43091.7363097779, delta_loss = 1414.7428
BPRRecommender iter 6: loss = 41241.872299906936, delta_loss = 1849.864
BPRRecommender iter 7: loss = 38985.26623065454, delta_loss = 2256.606
BPRRecommender iter 8: loss = 36583.792131227, delta_loss = 2401.474
BPRRecommender iter 9: loss = 34096.19578667925, delta_loss = 2487.5964
BPRRecommender iter 10: loss = 31876.405277866328, delta_loss = 2219.7905
BPRRecommender iter 11: loss = 29967.89804195514, delta_loss = 1908.5072
BPRRecommender iter 12: loss = 28108.761434537486, delta_loss = 1859.1366
BPRRecommender iter 13: loss = 26693.012327772478, delta_loss = 1415.7491
BPRRecommender iter 14: loss = 25466.791723385573, delta_loss = 1226.2206
BPRRecommender iter 15: loss = 24218.81656464389, delta_loss = 1247.9752
BPRRecommender iter 16: loss = 23219.77425689008, delta_loss = 999.0423
BPRRecommender iter 17: loss = 22604.28170892394, delta_loss = 615.49255
BPRRecommender iter 18: loss = 21870.784624287946, delta_loss = 733.4971
BPRRecommender iter 19: loss = 21189.990545681543, delta_loss = 680.79407
BPRRecommender iter 20: loss = 20699.7047361501, delta_loss = 490.2858
BPRRecommender iter 21: loss = 20233.753569616132, delta_loss = 465.95117
BPRRecommender iter 22: loss = 19775.983882337627, delta_loss = 457.76968
BPRRecommender iter 23: loss = 19367.14548054019, delta_loss = 408.8384
BPRRecommender iter 24: loss = 19132.151804328987, delta_loss = 234.99368
BPRRecommender iter 25: loss = 18719.92009519154, delta_loss = 412.23172
BPRRecommender iter 26: loss = 18431.54022111985, delta_loss = 288.37988
BPRRecommender iter 27: loss = 18298.26649666442, delta_loss = 133.27373
BPRRecommender iter 28: loss = 17999.731554817998, delta_loss = 298.53494
BPRRecommender iter 29: loss = 17687.90272189222, delta_loss = 311.82883
BPRRecommender iter 30: loss = 17685.364275742377, delta_loss = 2.5384462
BPRRecommender iter 31: loss = 17529.009465662853, delta_loss = 156.35481
BPRRecommender iter 32: loss = 17276.732802016995, delta_loss = 252.27666
BPRRecommender iter 33: loss = 17235.17254890189, delta_loss = 41.560253
BPRRecommender iter 34: loss = 17201.32761695922, delta_loss = 33.844933
BPRRecommender iter 35: loss = 17109.025600550816, delta_loss = 92.30202
BPRRecommender iter 36: loss = 17013.550323240837, delta_loss = 95.47528
BPRRecommender iter 37: loss = 16934.279168326037, delta_loss = 79.27116
BPRRecommender iter 38: loss = 16780.818639942572, delta_loss = 153.46053
BPRRecommender iter 39: loss = 16753.15217290646, delta_loss = 27.666468
BPRRecommender iter 40: loss = 16713.564779813227, delta_loss = 39.587395
Job Train completed.
Job End.
Evaluator value:RECALL top 15 is 0.07699127395643797
Evaluator value:RR top 15 is 0.12443707559206821
Evaluator value:Novelty top 15 is 66.70410136955657
Evaluator value:Entropy top 15 is 66.63151608996495
Evaluator value:AUC top 15 is 0.6614557508486981
Evaluator value:AP top 15 is 0.028721598859497162
Evaluator value:PRECISION top 15 is 0.027719821162444057
Evaluator value:NDCG top 15 is 0.0635336525627148
Result path is D:/Works/论文/dataSet/experimentData/Foursquare/process/experiment_8_31/result//preference_uvc.txt-bpr-output/bpr
Dataset: ...experiment_8_31//preference_uvc.txt
All dataset files [D:\Works\论文\dataSet\experimentData\Foursquare\process\experiment_8_31\preference_uvc.txt]
All dataset files size 216277
Now loading dataset file preference_uvc
Transform data to Convertor successfully!
Dataset: ...ss/experiment_8_31//newTest_uvc.txt
All dataset files [D:\Works\论文\dataSet\experimentData\Foursquare\process\experiment_8_31\newTest_uvc.txt]
All dataset files size 18322010
Now loading dataset file newTest_uvc
Split data to train Set and test Set successfully!
Data size of training is 13024
Data size of testing is 3595
Job Setup completed.
BPRRecommender iter 1: loss = 46661.00022404035, delta_loss = -46661.0
BPRRecommender iter 2: loss = 46140.30003449343, delta_loss = 520.7002
BPRRecommender iter 3: loss = 45478.39489970328, delta_loss = 661.90515
BPRRecommender iter 4: loss = 44506.4790622501, delta_loss = 971.91583
BPRRecommender iter 5: loss = 43091.7363097779, delta_loss = 1414.7428
BPRRecommender iter 6: loss = 41241.872299906936, delta_loss = 1849.864
BPRRecommender iter 7: loss = 38985.26623065454, delta_loss = 2256.606
BPRRecommender iter 8: loss = 36583.792131227, delta_loss = 2401.474
BPRRecommender iter 9: loss = 34096.19578667925, delta_loss = 2487.5964
BPRRecommender iter 10: loss = 31876.405277866328, delta_loss = 2219.7905
BPRRecommender iter 11: loss = 29967.89804195514, delta_loss = 1908.5072
BPRRecommender iter 12: loss = 28108.761434537486, delta_loss = 1859.1366
BPRRecommender iter 13: loss = 26693.012327772478, delta_loss = 1415.7491
BPRRecommender iter 14: loss = 25466.791723385573, delta_loss = 1226.2206
BPRRecommender iter 15: loss = 24218.81656464389, delta_loss = 1247.9752
BPRRecommender iter 16: loss = 23219.77425689008, delta_loss = 999.0423
BPRRecommender iter 17: loss = 22604.28170892394, delta_loss = 615.49255
BPRRecommender iter 18: loss = 21870.784624287946, delta_loss = 733.4971
BPRRecommender iter 19: loss = 21189.990545681543, delta_loss = 680.79407
BPRRecommender iter 20: loss = 20699.7047361501, delta_loss = 490.2858
BPRRecommender iter 21: loss = 20233.753569616132, delta_loss = 465.95117
BPRRecommender iter 22: loss = 19775.983882337627, delta_loss = 457.76968
BPRRecommender iter 23: loss = 19367.14548054019, delta_loss = 408.8384
BPRRecommender iter 24: loss = 19132.151804328987, delta_loss = 234.99368
BPRRecommender iter 25: loss = 18719.92009519154, delta_loss = 412.23172
BPRRecommender iter 26: loss = 18431.54022111985, delta_loss = 288.37988
BPRRecommender iter 27: loss = 18298.26649666442, delta_loss = 133.27373
BPRRecommender iter 28: loss = 17999.731554817998, delta_loss = 298.53494
BPRRecommender iter 29: loss = 17687.90272189222, delta_loss = 311.82883
BPRRecommender iter 30: loss = 17685.364275742377, delta_loss = 2.5384462
BPRRecommender iter 31: loss = 17529.009465662853, delta_loss = 156.35481
BPRRecommender iter 32: loss = 17276.732802016995, delta_loss = 252.27666
BPRRecommender iter 33: loss = 17235.17254890189, delta_loss = 41.560253
BPRRecommender iter 34: loss = 17201.32761695922, delta_loss = 33.844933
BPRRecommender iter 35: loss = 17109.025600550816, delta_loss = 92.30202
BPRRecommender iter 36: loss = 17013.550323240837, delta_loss = 95.47528
BPRRecommender iter 37: loss = 16934.279168326037, delta_loss = 79.27116
BPRRecommender iter 38: loss = 16780.818639942572, delta_loss = 153.46053
BPRRecommender iter 39: loss = 16753.15217290646, delta_loss = 27.666468
BPRRecommender iter 40: loss = 16713.564779813227, delta_loss = 39.587395
Job Train completed.
Job End.
Evaluator value:AUC top 20 is 0.6858857669063433
Evaluator value:NDCG top 20 is 0.06948539347353316
Evaluator value:Entropy top 20 is 83.81004770765456
Evaluator value:PRECISION top 20 is 0.02481371087928473
Evaluator value:Novelty top 20 is 90.76153237814256
Evaluator value:RR top 20 is 0.12723641728079224
Evaluator value:AP top 20 is 0.029758104863733238
Evaluator value:RECALL top 20 is 0.09377942795381901
Result path is D:/Works/论文/dataSet/experimentData/Foursquare/process/experiment_8_31/result//preference_uvc.txt-bpr-output/bpr
Dataset: ...experiment_8_31//preference_uvc.txt
All dataset files [D:\Works\论文\dataSet\experimentData\Foursquare\process\experiment_8_31\preference_uvc.txt]
All dataset files size 216277
Now loading dataset file preference_uvc
Transform data to Convertor successfully!
Dataset: ...ss/experiment_8_31//newTest_uvc.txt
All dataset files [D:\Works\论文\dataSet\experimentData\Foursquare\process\experiment_8_31\newTest_uvc.txt]
All dataset files size 18322010
Now loading dataset file newTest_uvc
Split data to train Set and test Set successfully!
Data size of training is 13024
Data size of testing is 3595
Job Setup completed.
BPRRecommender iter 1: loss = 46661.00022404035, delta_loss = -46661.0
BPRRecommender iter 2: loss = 46140.30003449343, delta_loss = 520.7002
BPRRecommender iter 3: loss = 45478.39489970328, delta_loss = 661.90515
BPRRecommender iter 4: loss = 44506.4790622501, delta_loss = 971.91583
BPRRecommender iter 5: loss = 43091.7363097779, delta_loss = 1414.7428
BPRRecommender iter 6: loss = 41241.872299906936, delta_loss = 1849.864
BPRRecommender iter 7: loss = 38985.26623065454, delta_loss = 2256.606
BPRRecommender iter 8: loss = 36583.792131227, delta_loss = 2401.474
BPRRecommender iter 9: loss = 34096.19578667925, delta_loss = 2487.5964
BPRRecommender iter 10: loss = 31876.405277866328, delta_loss = 2219.7905
BPRRecommender iter 11: loss = 29967.89804195514, delta_loss = 1908.5072
BPRRecommender iter 12: loss = 28108.761434537486, delta_loss = 1859.1366
BPRRecommender iter 13: loss = 26693.012327772478, delta_loss = 1415.7491
BPRRecommender iter 14: loss = 25466.791723385573, delta_loss = 1226.2206
BPRRecommender iter 15: loss = 24218.81656464389, delta_loss = 1247.9752
BPRRecommender iter 16: loss = 23219.77425689008, delta_loss = 999.0423
BPRRecommender iter 17: loss = 22604.28170892394, delta_loss = 615.49255
BPRRecommender iter 18: loss = 21870.784624287946, delta_loss = 733.4971
BPRRecommender iter 19: loss = 21189.990545681543, delta_loss = 680.79407
BPRRecommender iter 20: loss = 20699.7047361501, delta_loss = 490.2858
BPRRecommender iter 21: loss = 20233.753569616132, delta_loss = 465.95117
BPRRecommender iter 22: loss = 19775.983882337627, delta_loss = 457.76968
BPRRecommender iter 23: loss = 19367.14548054019, delta_loss = 408.8384
BPRRecommender iter 24: loss = 19132.151804328987, delta_loss = 234.99368
BPRRecommender iter 25: loss = 18719.92009519154, delta_loss = 412.23172
BPRRecommender iter 26: loss = 18431.54022111985, delta_loss = 288.37988
BPRRecommender iter 27: loss = 18298.26649666442, delta_loss = 133.27373
BPRRecommender iter 28: loss = 17999.731554817998, delta_loss = 298.53494
BPRRecommender iter 29: loss = 17687.90272189222, delta_loss = 311.82883
BPRRecommender iter 30: loss = 17685.364275742377, delta_loss = 2.5384462
BPRRecommender iter 31: loss = 17529.009465662853, delta_loss = 156.35481
BPRRecommender iter 32: loss = 17276.732802016995, delta_loss = 252.27666
BPRRecommender iter 33: loss = 17235.17254890189, delta_loss = 41.560253
BPRRecommender iter 34: loss = 17201.32761695922, delta_loss = 33.844933
BPRRecommender iter 35: loss = 17109.025600550816, delta_loss = 92.30202
BPRRecommender iter 36: loss = 17013.550323240837, delta_loss = 95.47528
BPRRecommender iter 37: loss = 16934.279168326037, delta_loss = 79.27116
BPRRecommender iter 38: loss = 16780.818639942572, delta_loss = 153.46053
BPRRecommender iter 39: loss = 16753.15217290646, delta_loss = 27.666468
BPRRecommender iter 40: loss = 16713.564779813227, delta_loss = 39.587395
Job Train completed.
Job End.
Evaluator value:AUC top 50 is 0.7568298514751892
Evaluator value:RECALL top 50 is 0.15563718761147027
Evaluator value:NDCG top 50 is 0.0896689520970194
Evaluator value:Entropy top 50 is 171.3125552765328
Evaluator value:RR top 50 is 0.13193771695077114
Evaluator value:Novelty top 50 is 244.23473647884938
Evaluator value:PRECISION top 50 is 0.01654247391952298
Evaluator value:AP top 50 is 0.03270058763795935
Result path is D:/Works/论文/dataSet/experimentData/Foursquare/process/experiment_8_31/result//preference_uvc.txt-bpr-output/bpr
Dataset: ...experiment_8_31//preference_uvc.txt
All dataset files [D:\Works\论文\dataSet\experimentData\Foursquare\process\experiment_8_31\preference_uvc.txt]
All dataset files size 216277
Now loading dataset file preference_uvc
Transform data to Convertor successfully!
Dataset: ...ss/experiment_8_31//newTest_uvc.txt
All dataset files [D:\Works\论文\dataSet\experimentData\Foursquare\process\experiment_8_31\newTest_uvc.txt]
All dataset files size 18322010
Now loading dataset file newTest_uvc
Split data to train Set and test Set successfully!
Data size of training is 13024
Data size of testing is 3595
Job Setup completed.
BPRRecommender iter 1: loss = 46661.00022404035, delta_loss = -46661.0
BPRRecommender iter 2: loss = 46140.30003449343, delta_loss = 520.7002
BPRRecommender iter 3: loss = 45478.39489970328, delta_loss = 661.90515
BPRRecommender iter 4: loss = 44506.4790622501, delta_loss = 971.91583
BPRRecommender iter 5: loss = 43091.7363097779, delta_loss = 1414.7428
BPRRecommender iter 6: loss = 41241.872299906936, delta_loss = 1849.864
BPRRecommender iter 7: loss = 38985.26623065454, delta_loss = 2256.606
BPRRecommender iter 8: loss = 36583.792131227, delta_loss = 2401.474
BPRRecommender iter 9: loss = 34096.19578667925, delta_loss = 2487.5964
BPRRecommender iter 10: loss = 31876.405277866328, delta_loss = 2219.7905
BPRRecommender iter 11: loss = 29967.89804195514, delta_loss = 1908.5072
BPRRecommender iter 12: loss = 28108.761434537486, delta_loss = 1859.1366
BPRRecommender iter 13: loss = 26693.012327772478, delta_loss = 1415.7491
BPRRecommender iter 14: loss = 25466.791723385573, delta_loss = 1226.2206
BPRRecommender iter 15: loss = 24218.81656464389, delta_loss = 1247.9752
BPRRecommender iter 16: loss = 23219.77425689008, delta_loss = 999.0423
BPRRecommender iter 17: loss = 22604.28170892394, delta_loss = 615.49255
BPRRecommender iter 18: loss = 21870.784624287946, delta_loss = 733.4971
BPRRecommender iter 19: loss = 21189.990545681543, delta_loss = 680.79407
BPRRecommender iter 20: loss = 20699.7047361501, delta_loss = 490.2858
BPRRecommender iter 21: loss = 20233.753569616132, delta_loss = 465.95117
BPRRecommender iter 22: loss = 19775.983882337627, delta_loss = 457.76968
BPRRecommender iter 23: loss = 19367.14548054019, delta_loss = 408.8384
BPRRecommender iter 24: loss = 19132.151804328987, delta_loss = 234.99368
BPRRecommender iter 25: loss = 18719.92009519154, delta_loss = 412.23172
BPRRecommender iter 26: loss = 18431.54022111985, delta_loss = 288.37988
BPRRecommender iter 27: loss = 18298.26649666442, delta_loss = 133.27373
BPRRecommender iter 28: loss = 17999.731554817998, delta_loss = 298.53494
BPRRecommender iter 29: loss = 17687.90272189222, delta_loss = 311.82883
BPRRecommender iter 30: loss = 17685.364275742377, delta_loss = 2.5384462
BPRRecommender iter 31: loss = 17529.009465662853, delta_loss = 156.35481
BPRRecommender iter 32: loss = 17276.732802016995, delta_loss = 252.27666
BPRRecommender iter 33: loss = 17235.17254890189, delta_loss = 41.560253
BPRRecommender iter 34: loss = 17201.32761695922, delta_loss = 33.844933
BPRRecommender iter 35: loss = 17109.025600550816, delta_loss = 92.30202
BPRRecommender iter 36: loss = 17013.550323240837, delta_loss = 95.47528
BPRRecommender iter 37: loss = 16934.279168326037, delta_loss = 79.27116
BPRRecommender iter 38: loss = 16780.818639942572, delta_loss = 153.46053
BPRRecommender iter 39: loss = 16753.15217290646, delta_loss = 27.666468
BPRRecommender iter 40: loss = 16713.564779813227, delta_loss = 39.587395
Job Train completed.
Job End.
Evaluator value:RECALL top 15 is 0.07699127395643797
Evaluator value:RR top 15 is 0.12443707559206821
Evaluator value:Novelty top 15 is 66.70410136955657
Evaluator value:Entropy top 15 is 66.63151608996495
Evaluator value:AUC top 15 is 0.6614557508486981
Evaluator value:AP top 15 is 0.028721598859497162
Evaluator value:PRECISION top 15 is 0.027719821162444057
Evaluator value:NDCG top 15 is 0.0635336525627148
Result path is D:/Works/论文/dataSet/experimentData/Foursquare/process/experiment_8_31/result//preference_uvc.txt-bpr-output/bpr
Dataset: ...experiment_8_31//preference_uvc.txt
All dataset files [D:\Works\论文\dataSet\experimentData\Foursquare\process\experiment_8_31\preference_uvc.txt]
All dataset files size 216277
Now loading dataset file preference_uvc
Transform data to Convertor successfully!
Dataset: ...ss/experiment_8_31//newTest_uvc.txt
All dataset files [D:\Works\论文\dataSet\experimentData\Foursquare\process\experiment_8_31\newTest_uvc.txt]
All dataset files size 18322010
Now loading dataset file newTest_uvc
Split data to train Set and test Set successfully!
Data size of training is 13024
Data size of testing is 3595
Job Setup completed.
BPRRecommender iter 1: loss = 46661.00022404035, delta_loss = -46661.0
BPRRecommender iter 2: loss = 46140.30003449343, delta_loss = 520.7002
BPRRecommender iter 3: loss = 45478.39489970328, delta_loss = 661.90515
BPRRecommender iter 4: loss = 44506.4790622501, delta_loss = 971.91583
BPRRecommender iter 5: loss = 43091.7363097779, delta_loss = 1414.7428
BPRRecommender iter 6: loss = 41241.872299906936, delta_loss = 1849.864
BPRRecommender iter 7: loss = 38985.26623065454, delta_loss = 2256.606
BPRRecommender iter 8: loss = 36583.792131227, delta_loss = 2401.474
BPRRecommender iter 9: loss = 34096.19578667925, delta_loss = 2487.5964
BPRRecommender iter 10: loss = 31876.405277866328, delta_loss = 2219.7905
BPRRecommender iter 11: loss = 29967.89804195514, delta_loss = 1908.5072
BPRRecommender iter 12: loss = 28108.761434537486, delta_loss = 1859.1366
BPRRecommender iter 13: loss = 26693.012327772478, delta_loss = 1415.7491
BPRRecommender iter 14: loss = 25466.791723385573, delta_loss = 1226.2206
BPRRecommender iter 15: loss = 24218.81656464389, delta_loss = 1247.9752
BPRRecommender iter 16: loss = 23219.77425689008, delta_loss = 999.0423
BPRRecommender iter 17: loss = 22604.28170892394, delta_loss = 615.49255
BPRRecommender iter 18: loss = 21870.784624287946, delta_loss = 733.4971
BPRRecommender iter 19: loss = 21189.990545681543, delta_loss = 680.79407
BPRRecommender iter 20: loss = 20699.7047361501, delta_loss = 490.2858
BPRRecommender iter 21: loss = 20233.753569616132, delta_loss = 465.95117
BPRRecommender iter 22: loss = 19775.983882337627, delta_loss = 457.76968
BPRRecommender iter 23: loss = 19367.14548054019, delta_loss = 408.8384
BPRRecommender iter 24: loss = 19132.151804328987, delta_loss = 234.99368
BPRRecommender iter 25: loss = 18719.92009519154, delta_loss = 412.23172
BPRRecommender iter 26: loss = 18431.54022111985, delta_loss = 288.37988
BPRRecommender iter 27: loss = 18298.26649666442, delta_loss = 133.27373
BPRRecommender iter 28: loss = 17999.731554817998, delta_loss = 298.53494
BPRRecommender iter 29: loss = 17687.90272189222, delta_loss = 311.82883
BPRRecommender iter 30: loss = 17685.364275742377, delta_loss = 2.5384462
BPRRecommender iter 31: loss = 17529.009465662853, delta_loss = 156.35481
BPRRecommender iter 32: loss = 17276.732802016995, delta_loss = 252.27666
BPRRecommender iter 33: loss = 17235.17254890189, delta_loss = 41.560253
BPRRecommender iter 34: loss = 17201.32761695922, delta_loss = 33.844933
BPRRecommender iter 35: loss = 17109.025600550816, delta_loss = 92.30202
BPRRecommender iter 36: loss = 17013.550323240837, delta_loss = 95.47528
BPRRecommender iter 37: loss = 16934.279168326037, delta_loss = 79.27116
BPRRecommender iter 38: loss = 16780.818639942572, delta_loss = 153.46053
BPRRecommender iter 39: loss = 16753.15217290646, delta_loss = 27.666468
BPRRecommender iter 40: loss = 16713.564779813227, delta_loss = 39.587395
Job Train completed.
Job End.
Evaluator value:PRECISION top 10 is 0.03263785394932941
Evaluator value:AP top 10 is 0.027946068572044354
Evaluator value:AUC top 10 is 0.6370009521631681
Evaluator value:RECALL top 10 is 0.0628304736083252
Evaluator value:NDCG top 10 is 0.058113928804260306
Evaluator value:Entropy top 10 is 47.85719459125794
Evaluator value:RR top 10 is 0.12039777162727987
Evaluator value:Novelty top 10 is 43.14768766631461
Result path is D:/Works/论文/dataSet/experimentData/Foursquare/process/experiment_8_31/result//preference_uvc.txt-bpr-output/bpr
Dataset: ../data/filmtrust/rating
All dataset files [..\data\filmtrust\rating\ratings_0.txt, ..\data\filmtrust\rating\ratings_1.txt, ..\data\filmtrust\rating\ratings_2.txt, ..\data\filmtrust\rating\ratings_3.txt]
All dataset files size 411942
Now loading dataset file ratings_0
Now loading dataset file ratings_1
Now loading dataset file ratings_2
Now loading dataset file ratings_3
Transform data to Convertor successfully!
Split data to train Set and test Set successfully!
Data size of training is 28408
Data size of testing is 7086
Job Setup completed.
Job Train completed.
Job End.
Evaluator value:PRECISION top 10 is 0.34767166535122473
Evaluator value:AP top 10 is 0.4523395548183904
Evaluator value:AUC top 10 is 0.9323629703602099
Evaluator value:RECALL top 10 is 0.637761713030289
Evaluator value:NDCG top 10 is 0.5521263644626981
Evaluator value:Entropy top 10 is 16.24742483774977
Evaluator value:RR top 10 is 0.6030004635371653
Evaluator value:Novelty top 10 is 11.160534440131611
Result path is ../result/filmtrust/rating-mostpopular-output/mostpopular
Dataset: ...experiment_8_31//preference_uvc.txt
All dataset files [D:\Works\论文\dataSet\experimentData\Foursquare\process\experiment_8_31\preference_uvc.txt]
All dataset files size 216277
Now loading dataset file preference_uvc
Transform data to Convertor successfully!
Dataset: ...ss/experiment_8_31//newTest_uvc.txt
All dataset files [D:\Works\论文\dataSet\experimentData\Foursquare\process\experiment_8_31\newTest_uvc.txt]
All dataset files size 18322010
Now loading dataset file newTest_uvc
Split data to train Set and test Set successfully!
Data size of training is 13024
Data size of testing is 3595
Job Setup completed.
Job Train completed.
Job End.
Evaluator value:PRECISION top 10 is 0.05171385991058145
Evaluator value:AP top 10 is 0.06684715026928147
Evaluator value:AUC top 10 is 0.7101833900196189
Evaluator value:RECALL top 10 is 0.11666001088133521
Evaluator value:NDCG top 10 is 0.11888221246032098
Evaluator value:Entropy top 10 is 4.224520522656229
Evaluator value:RR top 10 is 0.2485782887422231
Evaluator value:Novelty top 10 is 27.02590861284851
Result path is D:/Works/论文/dataSet/experimentData/Foursquare/process/experiment_8_31/result//preference_uvc.txt-mostpopular-output/mostpopular
